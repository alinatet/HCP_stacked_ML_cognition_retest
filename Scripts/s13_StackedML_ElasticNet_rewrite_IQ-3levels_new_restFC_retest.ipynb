{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTANT !\n",
    "\n",
    "# In the first order need to set the number of CPU \n",
    "# for calculation before launching (depends on computer's number of cores)\n",
    "n_jobs= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date, datetime\n",
    "import warnings\n",
    "\n",
    "import matplotlib.axis as axis\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import scipy.stats as st\n",
    "\n",
    "from nilearn import image as nli\n",
    "from nilearn import plotting\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_2(z, control, index):    #age+gender == 2\n",
    "    #z should be a series\n",
    "    #control is a feature table\n",
    "    #index for indexing\n",
    "    \n",
    "    #shrink data to local train index\n",
    "    y = z.reindex(index = index)\n",
    "    X = control.reindex(index = index)\n",
    "\n",
    "    #drop Nan in target and clean this subj from features\n",
    "    y = y.dropna()\n",
    "    X = X.loc[y.index,:]\n",
    "    ind_y = np.array(y.index)\n",
    "    \n",
    "    #Centralize target by y_i-y_mean\n",
    "    y= pd.DataFrame([i-y.mean() for i in y], index=y.index)    \n",
    "    #y_real = y\n",
    "    \n",
    "    #reshaping data\n",
    "    X = X.values\n",
    "    y = y.values.reshape(-1, 1).ravel()\n",
    "    \n",
    "    #fill Nan in X\n",
    "    X = SimpleImputer(strategy='mean').fit_transform(X)\n",
    "    \n",
    "    #Standartize X\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    #Fit to the training set\n",
    "    y_pred = LinearRegression().fit(X, y).predict(X)\n",
    "    \n",
    "    y_res = y - y_pred\n",
    "    \n",
    "    return y_res, ind_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_mov_feature(z, control, mov, index): #age+gender+each specific task movement == 3\n",
    "    #z should be a table of features\n",
    "    #mov should be a series with movements for a specific modality\n",
    "    \n",
    "    #shrink data to local train index\n",
    "    z = z.reindex(index = index)\n",
    "    control = control.reindex(index = index)\n",
    "    mov = mov.reindex(index = index) \n",
    "    ind = z.index\n",
    "    #concal control with mov\n",
    "    cont = control\n",
    "    cont['mov'] = mov\n",
    "    \n",
    "    #loop\n",
    "    dct = {}\n",
    "    col_name = z.columns\n",
    "    for col in col_name:\n",
    "        y = z[col]\n",
    "        X = cont\n",
    "        \n",
    "        #Centralize target by y_i-y_mean\n",
    "        y= pd.DataFrame([i-y.mean() for i in y], index=y.index) \n",
    "        \n",
    "        #reshaping data\n",
    "        X = X.values\n",
    "        y = y.values.reshape(-1, 1).ravel()\n",
    "\n",
    "        #fill Nan in X\n",
    "        X = SimpleImputer(strategy='mean').fit_transform(X)\n",
    "\n",
    "        #Standartize X\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "\n",
    "        #Fit to the training set\n",
    "        y_pred = LinearRegression().fit(X, y).predict(X)\n",
    "\n",
    "        y_res = y - y_pred\n",
    "        \n",
    "        dct[col] = y_res\n",
    "    \n",
    "    df_t = pd.DataFrame(dct, index = ind)\n",
    "    \n",
    "    return df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elnet(X, y):\n",
    "\n",
    "    #drop Nan in target and clean this subj from features\n",
    "    y = y.dropna()\n",
    "    X = X.loc[y.index,:]\n",
    "    ind_y = np.array(y.index)\n",
    "      \n",
    "    y_real=y\n",
    "    \n",
    "    #reshaping data\n",
    "    X = X.values\n",
    "    y = y.values.reshape(-1, 1).ravel()\n",
    "    \n",
    "    #fill Nan in X\n",
    "    X = SimpleImputer(strategy='mean').fit_transform(X)\n",
    "    \n",
    "    #Standartize X\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    # Setup the pipeline steps:\n",
    "    steps = [('elasticnet', ElasticNet(random_state=42))]\n",
    "\n",
    "    # Create the pipeline: pipeline \n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    # Specify the hyperparameter space\n",
    "    parameters = {'elasticnet__alpha': np.logspace(-6, 4, 500),\n",
    "                  'elasticnet__l1_ratio':np.linspace(0,1,100)}\n",
    "\n",
    "    # Create the GridSearchCV object:\n",
    "    gm_cv = GridSearchCV(pipeline, parameters, cv=5, n_jobs=n_jobs)\n",
    "    \n",
    "    # Fit to the training set\n",
    "    gm_cv.fit(X, y)\n",
    "    \n",
    "    #predict new y\n",
    "    y_pred = gm_cv.predict(X)\n",
    "\n",
    "    # Compute and print the metrics\n",
    "    acc = gm_cv.best_score_\n",
    "    bpar = gm_cv.best_params_\n",
    "    model = gm_cv.best_estimator_\n",
    "    mse = mean_squared_error(y_real, y_pred)\n",
    "    mae = mean_absolute_error(y_real, y_pred)\n",
    "    corr, _ = pearsonr(np.array(y_real.values.reshape(-1, 1).ravel(), dtype=float), np.array(y_pred, dtype=float))\n",
    "            \n",
    "    return bpar['elasticnet__alpha'], bpar['elasticnet__l1_ratio'], acc, mse, corr, model, y_pred, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reaply_ElNet(X, y, model):\n",
    "    # param should be pd.Series with indexes from model\n",
    "    \n",
    "    #drop Nan in target and clean this subj from features\n",
    "    y = y.dropna()\n",
    "    X = X.reindex(index =y.index)\n",
    "    ind_y = np.array(y.index)  # indexes as separate variable \n",
    "    \n",
    "    y_real = y\n",
    "\n",
    "    #reshaping data\n",
    "    X = X.values\n",
    "    y = y.values.reshape(-1, 1).ravel()\n",
    "    \n",
    "    #fill Nan in X\n",
    "    X = SimpleImputer(strategy='mean').fit_transform(X)\n",
    "    \n",
    "    #Standartize X\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    #predict new y\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # Compute and print the metrics\n",
    "    bacc = model.score(X, y)\n",
    "    mse = mean_squared_error(y_real, y_pred)\n",
    "    mae = mean_absolute_error(y_real, y_pred) \n",
    "    corr, _ = pearsonr(np.array(y_real.values.reshape(-1, 1).ravel(), dtype=float), np.array(y_pred, dtype=float))\n",
    "    \n",
    "    return y_pred, y_real, ind_y, bacc, mse, corr, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path to the tables folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/media/DataD800/Alina/retest_set/MLtables/'\n",
    "path_s1200 = '/media/DataD800/Alina/MLtables/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "#demography\n",
    "demo_retest_test2 = pd.read_csv(path+'demographics_table.csv', index_col=0)\n",
    "\n",
    "#targets table\n",
    "targ_retest_test2 = pd.read_csv(path+'cognition_table.csv', index_col=0)\n",
    "\n",
    "#features tables as dictionary\n",
    "features_retest_test2 = {\n",
    "    'emo':pd.read_csv(path+'emo_table.csv', index_col=0),\n",
    "    'gam':pd.read_csv(path+'gam_table.csv', index_col=0),\n",
    "    'lan':pd.read_csv(path+'lan_table.csv', index_col=0),\n",
    "    'mot':pd.read_csv(path+'mot_table.csv', index_col=0),\n",
    "    'rel':pd.read_csv(path+'rel_table.csv', index_col=0),\n",
    "    'soc':pd.read_csv(path+'soc_table.csv', index_col=0),\n",
    "    'wm':pd.read_csv(path+'wm_table.csv', index_col=0),\n",
    "    'cort':pd.read_csv(path+'cort_table.csv', index_col=0),\n",
    "    'subc':pd.read_csv(path+'subc_table.csv', index_col=0),\n",
    "    'surf':pd.read_csv(path+'surf_table.csv', index_col=0),\n",
    "    'rest':pd.read_csv(path+'rest_table_featfiltered.csv', index_col=0),\n",
    "    'VolBrain':pd.read_csv(path+'VolBrain_table.csv', index_col=0)\n",
    "}\n",
    "\n",
    "\n",
    "#table with movements (mean relative displacement Movement_RelativeRMS_mean.txt)\n",
    "movements_retest_test2 = pd.read_csv(path+'movement_table.csv', index_col=0)\n",
    "\n",
    "#create tables with 2 controling parameters: gender and age\n",
    "age_coded_retest_test2 = pd.Series(LabelEncoder().fit_transform(demo_retest_test2.loc[:,['Gender']]), index=demo_retest_test2.index, name='Gender')\n",
    "control_retest_test2 = pd.concat([age_coded_retest_test2, demo_retest_test2.loc[:, ['Age_in_Yrs']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "#demography\n",
    "demo_main = pd.read_csv(path_s1200+'demographics_table.csv', index_col=0)\n",
    "\n",
    "#targets table\n",
    "targ_main = pd.read_csv(path_s1200+'cognition_table.csv', index_col=0)\n",
    "\n",
    "#features tables as dictionary\n",
    "features_main = {\n",
    "    'emo':pd.read_csv(path_s1200+'emo_table.csv', index_col=0),\n",
    "    'gam':pd.read_csv(path_s1200+'gam_table.csv', index_col=0),\n",
    "    'lan':pd.read_csv(path_s1200+'lan_table.csv', index_col=0),\n",
    "    'mot':pd.read_csv(path_s1200+'mot_table.csv', index_col=0),\n",
    "    'rel':pd.read_csv(path_s1200+'rel_table.csv', index_col=0),\n",
    "    'soc':pd.read_csv(path_s1200+'soc_table.csv', index_col=0),\n",
    "    'wm':pd.read_csv(path_s1200+'wm_table.csv', index_col=0),\n",
    "    'cort':pd.read_csv(path_s1200+'cort_table.csv', index_col=0),\n",
    "    'subc':pd.read_csv(path_s1200+'subc_table.csv', index_col=0),\n",
    "    'surf':pd.read_csv(path_s1200+'surf_table.csv', index_col=0),\n",
    "    'rest':pd.read_csv(path_s1200+'rest_table_featfiltered.csv', index_col=0),\n",
    "    'VolBrain':pd.read_csv(path_s1200+'VolBrain_table.csv', index_col=0)\n",
    "}\n",
    "\n",
    "\n",
    "#table with movements (mean relative displacement Movement_RelativeRMS_mean.txt)\n",
    "movements_main = pd.read_csv(path_s1200+'movement_table.csv', index_col=0)\n",
    "\n",
    "#create tables with 2 controling parameters: gender and age\n",
    "age_coded_main = pd.Series(LabelEncoder().fit_transform(demo_main.loc[:,['Gender']]), index=demo_main.index, name='Gender')\n",
    "control_main = pd.concat([age_coded_main, demo_main.loc[:, ['Age_in_Yrs']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting main ito train and retest_test1\n",
    "\n",
    "demo_retest_test1 = demo_main.loc[demo_retest_test2.index,:]\n",
    "targ_retest_test1 = targ_main.loc[demo_retest_test2.index,:]\n",
    "movements_retest_test1 = movements_main.loc[demo_retest_test2.index,:]\n",
    "control_retest_test1 = control_main.loc[demo_retest_test2.index,:]\n",
    "features_retest_test1 = {}\n",
    "for key in features_main.keys():\n",
    "    features_retest_test1[key] = features_main[key].loc[demo_retest_test2.index,:]\n",
    "\n",
    "\n",
    "demo_train = demo_main.drop(demo_retest_test2.index, axis=0)\n",
    "targ_train = targ_main.drop(demo_retest_test2.index, axis=0)\n",
    "movements_train = movements_main.drop(demo_retest_test2.index, axis=0)\n",
    "control_train = control_main.drop(demo_retest_test2.index, axis=0)\n",
    "features_train = {}\n",
    "for key in features_main.keys():\n",
    "    features_train[key] = features_main[key].drop(demo_retest_test2.index, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Leave-P-groups out based on 8-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CogTotalComp_Unadj\n",
      " \n",
      "started to calculate ML\n",
      "2021-08-02 18:07:56.276605\n",
      " \n",
      "start 1st level  2021-08-02 18:07:56.276721\n",
      "start  emo 2021-08-02 18:09:33.430338\n",
      "start  gam 2021-08-02 18:31:00.417822\n",
      "start  lan 2021-08-02 19:03:18.109284\n",
      "start  mot 2021-08-02 19:34:30.261354\n",
      "start  rel 2021-08-02 21:46:44.014710\n",
      "start  soc 2021-08-02 23:58:58.957912\n",
      "start  wm 2021-08-03 00:20:18.265487\n",
      "start  cort 2021-08-03 00:49:48.681936\n",
      "start  subc 2021-08-03 01:05:13.422104\n",
      "start  surf 2021-08-03 01:08:04.197299\n",
      "start  rest 2021-08-03 01:21:33.449758\n",
      "start  VolBrain 2021-08-03 07:38:09.811280\n",
      " \n",
      "start 2nd level  2021-08-03 07:39:57.085022\n",
      "Checking single ML on test1 data  2021-08-03 07:39:57.085076\n",
      "Calculating stacked ML on test1 data  2021-08-03 07:41:00.274630\n",
      "set 1 2021-08-03 07:41:00.275308\n",
      "set 2 2021-08-03 07:43:20.885882\n",
      "set 3 2021-08-03 07:45:18.035307\n",
      " \n",
      "start 3rd level , retest1 2021-08-03 07:47:12.483973\n",
      "Checking single ML on retest1 data  2021-08-03 07:47:12.484435\n",
      "Calculating stacked ML on retest1 data  2021-08-03 07:47:21.420146\n",
      " \n",
      "start 3rd level , retest2 2021-08-03 07:47:22.952911\n",
      "Checking single ML on retest2 data  2021-08-03 07:47:22.953024\n",
      "Calculating stacked ML on retest2 data  2021-08-03 07:47:31.908658\n",
      " \n",
      "finished to calculate\n",
      "2021-08-03 07:47:31.916937\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "#for col in targ.columns:\n",
    "col = 'CogTotalComp_Unadj'  \n",
    "y_train = targ_train[col]\n",
    "y_retest_test1 = targ_retest_test1[col]\n",
    "y_retest_test2 = targ_retest_test2[col]\n",
    "\n",
    "\n",
    "print(y_train.name)\n",
    "\n",
    "#os.mkdir(path+'output_'+str(y_train.name))\n",
    "path_out = str(path+'output_'+str(y_train.name))\n",
    "\n",
    "\n",
    "#Split to local indexes for main train\n",
    "index_train, index_test = train_test_split(demo_train.index, test_size=0.4, random_state=42)\n",
    "\n",
    "#Local indices\n",
    "index_train = np.array(sorted(index_train), dtype='int') #for training modalities models\n",
    "index_test = np.array(sorted(index_test), dtype='int') #for testing modalities and training second level\n",
    "\n",
    "index_retest_test = np.array(sorted(demo_retest_test2.index), dtype='int')\n",
    "\n",
    "print(' ')\n",
    "print('started to calculate ML')\n",
    "print(datetime.now())\n",
    "print(' ')\n",
    "\n",
    "\n",
    "### 1st level ################################################################################\n",
    "\n",
    "#### Calculations of single ML models on index_train #################################### \n",
    "\n",
    "print('start 1st level ', datetime.now())\n",
    "\n",
    "#control for age+gen and age+gen+mov with sorting to index_train\n",
    "\n",
    "#control y (target) for age+gen\n",
    "p1, p2 = control_2(y_train, control_train, index_train) #where p1 = y_res (residuals), p2 = ind_y (index)\n",
    "y_res1 = pd.Series(p1, index = p2)\n",
    "\n",
    "#control modalities\n",
    "features_res1 = {}\n",
    "for key in features_train.keys():\n",
    "\n",
    "    #controlling tasks for 3 parameter (age+gen+mov)\n",
    "    if key in ['emo', 'gam', 'lan', 'mot', 'rel', 'soc', 'wm', 'rest']:\n",
    "        features_res1[key] = control_mov_feature(features_train[key], control_train, movements_train[key], index_train)\n",
    "\n",
    "    #controlling the remaining for 2 parameters (age+gen)\n",
    "    if key in ['cort', 'surf', 'subc', 'VolBrain']:\n",
    "        d = {}\n",
    "        for col in features_train[key].columns:\n",
    "            p1,p2 = control_2(features_train[key][col], control_train, index_train)\n",
    "            d[col] = p1\n",
    "        df= pd.DataFrame(d, index = p2)\n",
    "        features_res1[key] = df\n",
    "\n",
    "\n",
    "#Launch ElasticNet for all task(modalities) on index_train (1st level)\n",
    "\n",
    "dict_tasks={}\n",
    "dict_elnet_model={}\n",
    "dict_ypred1={}\n",
    "\n",
    "for key in list(features_res1.keys()):\n",
    "\n",
    "    print('start ', str(key), datetime.now())   #print start time of calculations\n",
    "\n",
    "    bpar1, bpar2, acc, mse, corr, model, y_pred1, mae = elnet(features_res1[key], y_res1) #ML\n",
    "    dict_tasks[key] = acc, mse, mae, corr, bpar1, bpar2 \n",
    "    dict_elnet_model[key] = model\n",
    "    dict_ypred1[key] = y_pred1\n",
    "df_tasks = pd.DataFrame(dict_tasks, index=['best score r2', 'mse', 'mae','corr', 'best alpha', 'best l1_ratio'])\n",
    "df_y_pred1 = pd.DataFrame(dict_ypred1, index=y_res1.index)\n",
    "\n",
    "\n",
    "###Save outputs from this step (models and all mod. perf.)\n",
    "\n",
    "#model\n",
    "for key in dict_elnet_model.keys():\n",
    "    joblib.dump(dict_elnet_model[key], (path_out+'/'+str(key)+'_elnet_model.sav'))\n",
    "\n",
    "#model performance\n",
    "df_tasks.to_csv(path_out+'/1level_train_perf_elnet.csv')\n",
    "\n",
    "#list of first level targets (observed and predicted)\n",
    "y_res1.to_csv(path_out+'/1level_train_y_real_residual_index.csv', header=None)\n",
    "df_y_pred1.to_csv(path_out+'/1level_train_y_pred_singleML.csv')\n",
    "\n",
    "\n",
    "### 2st level ################################################################################\n",
    "print(' ')\n",
    "print('start 2nd level ', datetime.now())\n",
    "\n",
    "#### L2 Testing single ML models on index_test #############################################\n",
    "\n",
    "print('Checking single ML on test1 data ', datetime.now())\n",
    "\n",
    "#control for age+gen and age+gen+mov with sorting to index_test\n",
    "\n",
    "#control y (target) for age+gen\n",
    "p1, p2 = control_2(y_train, control_train, index_test)\n",
    "y_res2 = pd.Series(p1, index = p2)\n",
    "\n",
    "#control modalities\n",
    "features_res2 = {}\n",
    "for key in features_train.keys():\n",
    "\n",
    "    #controlling tasks for 3 parameter (age+gen+mov)\n",
    "    if key in ['emo', 'gam', 'lan', 'mot', 'rel', 'soc', 'wm', 'rest']:\n",
    "        features_res2[key] = control_mov_feature(features_train[key], control_train, movements_train[key], index_test)\n",
    "\n",
    "    #controlling the remaining for 2 parameters (age+gen)\n",
    "    if key in ['cort', 'surf', 'subc', 'VolBrain']:\n",
    "        d = {}\n",
    "        for col in features_train[key].columns:\n",
    "            p1,p2 = control_2(features_train[key][col], control_train, index_test)\n",
    "            d[col] = p1\n",
    "        df= pd.DataFrame(d, index = p2)\n",
    "        features_res2[key] = df        \n",
    "\n",
    "\n",
    "#apply trained single models ElasticNet to new data , index_test\n",
    "\n",
    "dict_y_pred2={}\n",
    "dict_y_pred2_per={}\n",
    "for key in list(features_res2.keys()):\n",
    "    y_pred, y_real, ind_y, bacc, mse, corr, mae = reaply_ElNet(features_res2[key], y_res2, dict_elnet_model[key]) #ML\n",
    "    dict_y_pred2[key] = y_pred\n",
    "    dict_y_pred2_per[key] = bacc, mse, mae, corr\n",
    "\n",
    "df_y_pred2 = pd.DataFrame(dict_y_pred2, index=ind_y)\n",
    "df_y_pred2_per = pd.DataFrame(dict_y_pred2_per, index=['best score r2', 'mse', 'mae','corr'])\n",
    "\n",
    "\n",
    "###Save outputs from this step (models and all mod. perf.)\n",
    "\n",
    "#model performance\n",
    "df_y_pred2_per.to_csv(path_out+'/2level_test1_perf_elnet.csv')\n",
    "\n",
    "#list of first level targets (observed and predicted)\n",
    "y_res2.to_csv(path_out+'/2level_test1_y_real_residual_index.csv', header=None)\n",
    "df_y_pred2.to_csv(path_out+'/2level_test1_y_pred_singleML.csv')   \n",
    "\n",
    "\n",
    "\n",
    "#### L2 Calculating stacked ML models on index_test #############################################\n",
    "\n",
    "print('Calculating stacked ML on test1 data ', datetime.now())    \n",
    "\n",
    "\n",
    "#identifying sets for several stacked models\n",
    "set2 = ['emo', 'gam', 'lan', 'mot', 'rel', 'soc', 'wm']\n",
    "set3 = ['cort', 'subc', 'surf', 'rest', 'VolBrain']\n",
    "set1 = list(df_y_pred2.columns) #all existed modalities\n",
    "\n",
    "#for presetet sets\n",
    "dict_st_perf1={}\n",
    "dict_st_models={}\n",
    "dict_st_ypred1={}\n",
    "\n",
    "s=1\n",
    "for set_n in [set1, set2, set3]:\n",
    "    print('set '+str(s), datetime.now())\n",
    "\n",
    "    st_features = df_y_pred2.loc[:,set_n]\n",
    "\n",
    "    bpar1, bpar2, acc, mse, corr, model, y_pred3, mae = elnet(st_features, y_res2) #ML\n",
    "\n",
    "    dict_st_perf1['set'+str(s)] = acc, mse, mae, corr, bpar1, bpar2 \n",
    "    dict_st_models['set'+str(s)] = model\n",
    "    dict_st_ypred1['set'+str(s)] = y_pred3\n",
    "    s+=1\n",
    "\n",
    "df_st_perf1 = pd.DataFrame(dict_st_perf1, index=['best score r2', 'mse', 'mae','corr', 'best alpha', 'best l1_ratio'])\n",
    "df_st_ypred1 = pd.DataFrame(dict_st_ypred1, index=y_res2.index)        \n",
    "\n",
    "###Save outputs from this step (models and all mod. perf.)\n",
    "\n",
    "#models\n",
    "for key in dict_st_models.keys():\n",
    "    joblib.dump(dict_st_models[key], (path_out+'/'+str(key)+'_stacked_model.sav'))\n",
    "\n",
    "#performance and prediction\n",
    "df_st_perf1.to_csv(path_out+'/2level_test1_perf_stacked.csv')\n",
    "df_st_ypred1.to_csv(path_out+'/2level_test1_y_pred_stacked.csv')\n",
    "\n",
    "\n",
    "\n",
    "### 3rd level ################################################################################\n",
    "print(' ')\n",
    "print('start 3rd level , retest1', datetime.now())\n",
    "\n",
    "\n",
    "#### L3 Testing single ML models on retest1 #############################################\n",
    "\n",
    "print('Checking single ML on retest1 data ', datetime.now())\n",
    "\n",
    "#control for age+gen and age+gen+mov with sorting to index_retest_test\n",
    "\n",
    "#control y (target) for age+gen\n",
    "p1, p2 = control_2(y_retest_test1, control_retest_test1, index_retest_test)\n",
    "y_res3 = pd.Series(p1, index = p2)\n",
    "\n",
    "#control modalities\n",
    "features_res3 = {}\n",
    "for key in features_retest_test1.keys():\n",
    "\n",
    "    #controlling tasks for 3 parameter (age+gen+mov)\n",
    "    if key in ['emo', 'gam', 'lan', 'mot', 'rel', 'soc', 'wm', 'rest']:\n",
    "        features_res3[key] = control_mov_feature(features_retest_test1[key], control_retest_test1, movements_retest_test1[key], index_retest_test)\n",
    "\n",
    "    #controlling the remaining for 2 parameters (age+gen)\n",
    "    if key in ['cort', 'surf', 'subc', 'VolBrain']:\n",
    "        d = {}\n",
    "        for col in features_retest_test1[key].columns:\n",
    "            p1,p2 = control_2(features_retest_test1[key][col], control_retest_test1, index_retest_test)\n",
    "            d[col] = p1\n",
    "        df= pd.DataFrame(d, index = p2)\n",
    "        features_res3[key] = df        \n",
    "\n",
    "\n",
    "#apply trained single models ElasticNet to new data , test_index\n",
    "\n",
    "dict_y_pred3={}\n",
    "dict_y_pred3_per={}\n",
    "for key in list(features_res3.keys()):\n",
    "    y_pred, y_real, ind_y, bacc, mse, corr, mae = reaply_ElNet(features_res3[key], y_res3, dict_elnet_model[key]) #ML\n",
    "    dict_y_pred3[key] = y_pred\n",
    "    dict_y_pred3_per[key] = bacc, mse, mae, corr\n",
    "\n",
    "df_y_pred3 = pd.DataFrame(dict_y_pred3, index=ind_y)\n",
    "df_y_pred3_per = pd.DataFrame(dict_y_pred3_per, index=['best score r2', 'mse', 'mae','corr'])\n",
    "\n",
    "\n",
    "###Save outputs from this step (models and all mod. perf.)\n",
    "\n",
    "#model performance\n",
    "df_y_pred3_per.to_csv(path_out+'/3level_retest1_perf_elnet.csv')\n",
    "\n",
    "#list of first level targets (observed and predicted)\n",
    "y_res3.to_csv(path_out+'/3level_retest1_y_real_residual_index.csv', header=None)\n",
    "df_y_pred3.to_csv(path_out+'/3level_retest1_y_pred_singleML.csv')        \n",
    "\n",
    "\n",
    "#### L3 Testing stacked ML models on test_index #############################################\n",
    "\n",
    "print('Calculating stacked ML on retest1 data ', datetime.now()) \n",
    "\n",
    "#apply trained stacked models ElasticNet to new data , test_index\n",
    "\n",
    "#for presetet sets\n",
    "dict_st_perf2={}\n",
    "dict_st_ypred2={}\n",
    "s=1\n",
    "for set_n in [set1, set2, set3]:\n",
    "    ftrs = df_y_pred3.loc[:, set_n]\n",
    "    y_pred, y_real, ind_y, bacc, mse, corr, mae = reaply_ElNet(ftrs, y_res3, dict_st_models[('set'+str(s))]) #ML\n",
    "    dict_st_ypred2[('set'+str(s))] = y_pred\n",
    "    dict_st_perf2[('set'+str(s))] = bacc, mse, mae, corr\n",
    "    s+=1\n",
    "\n",
    "df_st_ypred2 = pd.DataFrame(dict_st_ypred2, index=ind_y)\n",
    "df_st_perf2 = pd.DataFrame(dict_st_perf2, index=['best score r2', 'mse', 'mae','corr'])        \n",
    "\n",
    "###Save outputs from this step (models and all mod. perf.)\n",
    "\n",
    "#performance and prediction\n",
    "df_st_perf2.to_csv(path_out+'/3level_retest1_perf_stacked.csv')\n",
    "df_st_ypred2.to_csv(path_out+'/3level_retest1_y_pred_stacked.csv') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 3rd level ################################################################################\n",
    "print(' ')\n",
    "print('start 3rd level , retest2', datetime.now())\n",
    "\n",
    "\n",
    "#### L3 Testing single ML models on retest2 #############################################\n",
    "\n",
    "print('Checking single ML on retest2 data ', datetime.now())\n",
    "\n",
    "#control for age+gen and age+gen+mov with sorting to index_retest_test\n",
    "\n",
    "#control y (target) for age+gen\n",
    "p1, p2 = control_2(y_retest_test2, control_retest_test2, index_retest_test)\n",
    "y_res3 = pd.Series(p1, index = p2)\n",
    "\n",
    "#control modalities\n",
    "features_res3 = {}\n",
    "for key in features_retest_test2.keys():\n",
    "\n",
    "    #controlling tasks for 3 parameter (age+gen+mov)\n",
    "    if key in ['emo', 'gam', 'lan', 'mot', 'rel', 'soc', 'wm', 'rest']:\n",
    "        features_res3[key] = control_mov_feature(features_retest_test2[key], control_retest_test2, movements_retest_test2[key], index_retest_test)\n",
    "\n",
    "    #controlling the remaining for 2 parameters (age+gen)\n",
    "    if key in ['cort', 'surf', 'subc', 'VolBrain']:\n",
    "        d = {}\n",
    "        for col in features_retest_test2[key].columns:\n",
    "            p1,p2 = control_2(features_retest_test2[key][col], control_retest_test2, index_retest_test)\n",
    "            d[col] = p1\n",
    "        df= pd.DataFrame(d, index = p2)\n",
    "        features_res3[key] = df        \n",
    "\n",
    "\n",
    "#apply trained single models ElasticNet to new data , test_index\n",
    "\n",
    "dict_y_pred3={}\n",
    "dict_y_pred3_per={}\n",
    "for key in list(features_res3.keys()):\n",
    "    y_pred, y_real, ind_y, bacc, mse, corr, mae = reaply_ElNet(features_res3[key], y_res3, dict_elnet_model[key]) #ML\n",
    "    dict_y_pred3[key] = y_pred\n",
    "    dict_y_pred3_per[key] = bacc, mse, mae, corr\n",
    "\n",
    "df_y_pred3 = pd.DataFrame(dict_y_pred3, index=ind_y)\n",
    "df_y_pred3_per = pd.DataFrame(dict_y_pred3_per, index=['best score r2', 'mse', 'mae','corr'])\n",
    "\n",
    "\n",
    "###Save outputs from this step (models and all mod. perf.)\n",
    "\n",
    "#model performance\n",
    "df_y_pred3_per.to_csv(path_out+'/3level_retest2_perf_elnet.csv')\n",
    "\n",
    "#list of first level targets (observed and predicted)\n",
    "y_res3.to_csv(path_out+'/3level_retest2_y_real_residual_index.csv', header=None)\n",
    "df_y_pred3.to_csv(path_out+'/3level_retest2_y_pred_singleML.csv')        \n",
    "\n",
    "\n",
    "#### L3 Testing stacked ML models on test_index #############################################\n",
    "\n",
    "print('Calculating stacked ML on retest2 data ', datetime.now()) \n",
    "\n",
    "#apply trained stacked models ElasticNet to new data , test_index\n",
    "\n",
    "#for presetet sets\n",
    "dict_st_perf2={}\n",
    "dict_st_ypred2={}\n",
    "s=1\n",
    "for set_n in [set1, set2, set3]:\n",
    "    ftrs = df_y_pred3.loc[:, set_n]\n",
    "    y_pred, y_real, ind_y, bacc, mse, corr, mae = reaply_ElNet(ftrs, y_res3, dict_st_models[('set'+str(s))]) #ML\n",
    "    dict_st_ypred2[('set'+str(s))] = y_pred\n",
    "    dict_st_perf2[('set'+str(s))] = bacc, mse, mae, corr\n",
    "    s+=1\n",
    "\n",
    "df_st_ypred2 = pd.DataFrame(dict_st_ypred2, index=ind_y)\n",
    "df_st_perf2 = pd.DataFrame(dict_st_perf2, index=['best score r2', 'mse', 'mae','corr'])        \n",
    "\n",
    "###Save outputs from this step (models and all mod. perf.)\n",
    "\n",
    "#performance and prediction\n",
    "df_st_perf2.to_csv(path_out+'/3level_retest2_perf_stacked.csv')\n",
    "df_st_ypred2.to_csv(path_out+'/3level_retest2_y_pred_stacked.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(' ')\n",
    "print('finished to calculate')\n",
    "print(datetime.now())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
